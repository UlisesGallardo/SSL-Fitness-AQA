{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_triplets:\n",
    "    def __init__(self, path_json, path_videos, path_bar_trajectory, save_path):\n",
    "        self.path_json = path_json\n",
    "        self.path_videos = path_videos\n",
    "        self.path_bar_trajectory = path_bar_trajectory\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def visualize(self, **images): \n",
    "        n = len(images)\n",
    "        plt.figure(figsize=(16, 5))\n",
    "        for i, (name, image) in enumerate(images.items()):\n",
    "            plt.subplot(1, n, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(' '.join(name.split('_')).title())\n",
    "            plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_sync_videos(self, path, cap1, cap2, name1 = \"\", name2 = \"\",save_video = False):\n",
    "        width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        if save_video:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            fps = 30\n",
    "            out = cv2.VideoWriter(\"./\"+name1+\"VS\"+name2+\".mp4\", fourcc, fps, (width*2,height))\n",
    "\n",
    "        for i,j in path:\n",
    "            cap1.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret1, frame1 = cap1.read()\n",
    "            cap2.set(cv2.CAP_PROP_POS_FRAMES, j)\n",
    "            ret2, frame2 = cap2.read()\n",
    "            if not ret1:\n",
    "                frame1 = np.zeros_like(frame2)\n",
    "            if not ret2:\n",
    "                frame2 = np.zeros_like(frame1)\n",
    "            frame2 = cv2.resize(frame2,(width, height)) \n",
    "            frame = cv2.resize(frame1,(width, height)) \n",
    "            frame = np.hstack((frame1, frame2))\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(frame)\n",
    "            plt.show()\n",
    "            if save_video: out.write(frame)\n",
    "        if save_video: out.release()\n",
    "\n",
    "    def get_frame(self, cap, i):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        res, frame = cap.read()\n",
    "        assert res\n",
    "        img1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return img1\n",
    "\n",
    "    def normalizar_posiciones_y(self, posiciones_y):\n",
    "        pos_min = min(posiciones_y)\n",
    "        pos_max = max(posiciones_y)\n",
    "        amplitud_vertical = pos_max - pos_min\n",
    "        if amplitud_vertical == 0:\n",
    "            factor_escala = 1\n",
    "        else:\n",
    "            factor_escala = 1 / amplitud_vertical\n",
    "        posiciones_y_normalizadas = np.array([[(pos - pos_min) * factor_escala] for pos in posiciones_y])\n",
    "        return posiciones_y_normalizadas\n",
    "\n",
    "    def get_trajectory(self, data, add_negative = False):\n",
    "        vertical_trajectory = np.zeros(len(data))\n",
    "        trayectoria_normalizada = []\n",
    "        negativos = []\n",
    "        for cnt, _ in enumerate(data):\n",
    "            if len(data[cnt][0]) > 0:\n",
    "                x1,y1,x2,y2,_ = data[cnt][0][0]\n",
    "                center_x, center_y = int(x1 + (x2-x1)/2) , int(y1 + (y2 - y1)/2)\n",
    "                vertical_trajectory[cnt] = center_y\n",
    "            else:\n",
    "                indices = np.nonzero(vertical_trajectory)[0]\n",
    "                if len(indices) > 0:\n",
    "                    j = indices[indices < cnt][-1]\n",
    "                    value = vertical_trajectory[j]\n",
    "                    vertical_trajectory[cnt] = value\n",
    "                negativos.append(cnt)\n",
    "\n",
    "        trayectoria_normalizada = self.normalizar_posiciones_y(vertical_trajectory)\n",
    "        if add_negative:\n",
    "            for x in negativos:\n",
    "                trayectoria_normalizada[x] = -1\n",
    "        return trayectoria_normalizada\n",
    "\n",
    "    def k_means_on_trajectory(self, i_frame, trajectory, k=4, max = False):\n",
    "        trajectory = np.array(trajectory)\n",
    "        kmedias = KMeans(n_clusters=k, random_state=0)\n",
    "        kmedias.fit(trajectory)\n",
    "        etiquetas = kmedias.labels_\n",
    "        positive_cluster = etiquetas[i_frame]\n",
    "        indices_cluster_diferente = np.where(etiquetas != positive_cluster)[0]\n",
    "        frame_negativo_index = np.random.choice(indices_cluster_diferente)\n",
    "        if max:\n",
    "            indices_cluster_diferente = np.where(etiquetas != positive_cluster)[0]\n",
    "            positive_trajectory = trajectory[i_frame]\n",
    "            distancias = np.linalg.norm(trajectory[indices_cluster_diferente] - positive_trajectory, axis=1)\n",
    "            frame_negativo_index = indices_cluster_diferente[np.argmax(distancias)]\n",
    "        return frame_negativo_index\n",
    "\n",
    "    def dividir_y_seleccionar_valores(self,arr):\n",
    "        n = len(arr)\n",
    "        segmentos = np.linspace(0, n, num=5, dtype=int)\n",
    "        rangos = [(segmentos[i], segmentos[i+1]) for i in range(4)]\n",
    "        \n",
    "        valores_seleccionados = []\n",
    "        for rango in rangos:\n",
    "            inicio, fin = rango\n",
    "            valores_seleccionados.append(np.random.choice(arr[inicio:fin]))\n",
    "        \n",
    "        return valores_seleccionados\n",
    "\n",
    "    def save_triplet(self, images, name1, name2, cnt):\n",
    "        for key, image in images.items():\n",
    "            save_filename = f\"{name1}+{name2}+{key}_{cnt}.jpg\"\n",
    "            save_filepath = os.path.join(self.save_path+key+\"/\", save_filename)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb = cv2.resize(image_rgb, (320, 320))\n",
    "            cv2.imwrite(save_filepath, image_rgb)\n",
    "\n",
    "    def get_triplets(self, plot_triplet = False, plot_video = False):\n",
    "        files = [f for f in os.listdir(self.path_json)]\n",
    "        files = sorted(files)\n",
    "        for j, file in enumerate(files):\n",
    "            name = file.split(\"-\")[0]            \n",
    "            path = os.path.join(self.path_json, file)\n",
    "            with open(path) as f:\n",
    "                data = json.load(f)\n",
    "            best = data\n",
    "\n",
    "            path_trajectory = os.path.join(self.path_bar_trajectory, name+\".json\")\n",
    "            with open(path_trajectory) as f:\n",
    "                data = json.load(f)\n",
    "            trajectory_anchor = self.get_trajectory(data, add_negative = True)\n",
    "            cnt = 0\n",
    "            for video_data in best:\n",
    "                another_name = video_data[0][0]\n",
    "                path = video_data[0][1]\n",
    "                cap1 = cv2.VideoCapture(self.path_videos+name+'.mp4')\n",
    "                cap2 = cv2.VideoCapture(self.path_videos+another_name+'.mp4')  \n",
    "                if plot_video:\n",
    "                    self.plot_sync_videos(path, cap1, cap2)\n",
    "                path_trajectory = os.path.join(self.path_bar_trajectory, another_name+\".json\")\n",
    "                with open(path_trajectory) as f:\n",
    "                    data = json.load(f)\n",
    "                trajectory_positive = self.get_trajectory(data, add_negative = True)\n",
    "                trajectory_ = self.get_trajectory(data)\n",
    "                arreglo = np.arange(len(path)) \n",
    "                valores_seleccionados = self.dividir_y_seleccionar_valores(arreglo)\n",
    "                for value in valores_seleccionados:\n",
    "                    x, y = path[value]\n",
    "                    if trajectory_anchor[x] == -1 or trajectory_positive[y] == -1:\n",
    "                        indices_validos_A = [i for i, valor in enumerate(trajectory_anchor) if valor != -1]\n",
    "                        indices_validos_B = [i for i, valor in enumerate(trajectory_positive) if valor != -1]\n",
    "                        if len(indices_validos_A) and len(indices_validos_B):\n",
    "                            for i, (a,b) in enumerate(path):\n",
    "                                if a in indices_validos_A and b in indices_validos_B:\n",
    "                                    x, y = path[i] \n",
    "                                    break\n",
    "                        else:\n",
    "                            continue\n",
    "                    z = self.k_means_on_trajectory(y,trajectory_)\n",
    "                    images = {'Anchor':self.get_frame(cap1,x),'Positive':self.get_frame(cap2,y),'Negative':self.get_frame(cap2,z)}\n",
    "                    self.save_triplet(images, name, another_name, cnt)\n",
    "                    if plot_triplet:\n",
    "                        self.visualize(**images)\n",
    "                    cnt+=1\n",
    "                \n",
    "            print(\"El video {} {} ha sido procesado\".format(name,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./alinged_videos_OHP_top/\"\n",
    "path_videos = \"./videos/\"\n",
    "path_bar_trajectory = \"./bar_trajectories_raw/\"\n",
    "save_path = \"./ssl_triplets_dataset_ohp/\"\n",
    "\n",
    "g = generate_triplets(path, path_videos, path_bar_trajectory, save_path)\n",
    "g.get_triplets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
