{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from  IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supservised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.file_list = self.get_file_list()\n",
    "\n",
    "    def get_file_list(self):\n",
    "        file_list = []\n",
    "        anchor_dir = os.path.join(self.root_dir, 'Anchor')\n",
    "        for file in os.listdir(anchor_dir):\n",
    "            if file.endswith('.jpg'):\n",
    "                file_path = os.path.join(anchor_dir, file)\n",
    "                file_list.append(file_path)\n",
    "        return file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def visualize(self, **images): \n",
    "        n = len(images)\n",
    "        plt.figure(figsize=(16, 5))\n",
    "        for i, (name, image) in enumerate(images.items()):\n",
    "            plt.subplot(1, n, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(' '.join(name.split('_')).title())\n",
    "            plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    def __getimages__(self, idx):\n",
    "        splits_pathA = os.path.dirname(self.file_list[idx])\n",
    "        anc_filename = os.path.basename(self.file_list[idx])\n",
    "        pos_filename = anc_filename.replace(\"Anchor\", \"Positive\")\n",
    "        splits_pathP = splits_pathA.replace(\"Anchor\", \"Positive\")\n",
    "        neg_filename = anc_filename.replace(\"Anchor\", \"Negative\")\n",
    "        splits_pathN = splits_pathA.replace(\"Anchor\", \"Negative\")\n",
    "        anchor_img = Image.open(os.path.join(splits_pathA, anc_filename)).convert('RGB')\n",
    "        pos_img = Image.open(os.path.join(splits_pathP, pos_filename)).convert('RGB')\n",
    "        neg_img = Image.open(os.path.join(splits_pathN, neg_filename)).convert('RGB')\n",
    "        return anchor_img, pos_img, neg_img\n",
    "\n",
    "    def __plot__triplet__(self, idx):\n",
    "        anchor_img, pos_img, neg_img = self.__getimages__(idx)\n",
    "        images = {'Anchor':anchor_img,'Positive':pos_img,'Negative':neg_img}    \n",
    "        self.visualize(**images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_img, pos_img, neg_img = self.__getimages__(idx)\n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "            pos_img = self.transform(pos_img)\n",
    "            neg_img = self.transform(neg_img)\n",
    "        \n",
    "        return anchor_img, pos_img, neg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./ssl_triplets_dataset_ohp/\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(320),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = ContrastiveDataset(root_dir, transform=transform)\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.7 * total_samples)\n",
    "test_size = int(0.15 * total_samples)\n",
    "valid_size = total_samples - train_size - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, valid_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107820"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__plot__triplet__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = models.resnet18(pretrained=True)\n",
    "        self.encoder.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.encoder.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.encoder.fc = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceRatioLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceRatioLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        epsilon = 1e-8\n",
    "        dist_pos = torch.sqrt(torch.sum(torch.pow(anchor - positive, 2), dim=1))\n",
    "        dist_neg = torch.sqrt(torch.sum(torch.pow(anchor - negative, 2), dim=1))\n",
    "        dist_pos = torch.exp(-dist_pos)\n",
    "        dist_neg = torch.exp(-dist_neg)\n",
    "        loss = torch.mean(torch.clamp(-torch.log((dist_pos+epsilon)/(dist_pos+dist_neg+epsilon)), min=0))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "model = ContrastiveModel()\n",
    "model.to(device)\n",
    "criterion = DistanceRatioLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        anchor_emb = model(anchor.to(device))\n",
    "        positive_emb = model(positive.to(device))\n",
    "        negative_emb = model(negative.to(device))\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{} ({:.2f}%)], Train Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, batch_idx+1, len(train_dataloader), (100*batch_idx+1)/len(train_dataloader), loss.item()))\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (anchor, positive, negative) in enumerate(valid_dataloader):\n",
    "            anchor_emb = model(anchor.to(device))\n",
    "            positive_emb = model(positive.to(device))\n",
    "            negative_emb = model(negative.to(device))\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(valid_dataloader)\n",
    "\n",
    "    # Imprimir la pérdida de entrenamiento y validación\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss, val_loss))\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, 'checkpoint_ssl_18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./checkpoint_ssl_18.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (anchor, positive, negative) in enumerate(test_dataloader):\n",
    "            anchor_emb = model(anchor.to(device))\n",
    "            positive_emb = model(positive.to(device))\n",
    "            negative_emb = model(negative.to(device))\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "    print('Test Loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
